{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade seaborn --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from timeit import default_timer as Timer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "The telecom operator Interconnect would like to be able to forecast their churn of clients. If it's discovered that a user is planning to leave, they will be offered promotional codes and special plan options. Interconnect's marketing team has collected some of their clientele's personal data, including information about their plans and contracts.\n",
    "\n",
    "### Data Description\n",
    "\n",
    "The data consists of files obtained from different sources:\n",
    "\n",
    "- `contract.csv` — contract information\n",
    "- `personal.csv` — the client's personal data\n",
    "- `internet.csv` — information about Internet services\n",
    "- `phone.csv` — information about telephone services\n",
    "\n",
    "In each file, the column `customerID` contains a unique code assigned to each client.\n",
    "\n",
    "The contract information is valid as of February 1, 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_data'></a>\n",
    "## Initial Data Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "\n",
    "path = '/datasets/final_provider/'\n",
    "if platform == 'darwin':\n",
    "    path = '/Users/stainer/Desktop/Jupyter/Data_Sets/final_provider/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    contract_data = pd.read_csv(path + 'contract.csv')\n",
    "    internet_data = pd.read_csv(path + 'internet.csv')\n",
    "    personal_data = pd.read_csv(path + 'personal.csv')\n",
    "    phone_data = pd.read_csv(path + 'phone.csv')\n",
    "    data_dict = {'contract':contract_data, 'internet':internet_data, 'personal':personal_data, 'phone':phone_data}\n",
    "    for data_set in data_dict:\n",
    "        df = data_dict[data_set]\n",
    "        df.columns = df.columns.str.lower()\n",
    "except:\n",
    "    print('Wrong file path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First glance on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contract'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7043, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>begindate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>type</th>\n",
       "      <th>paperlessbilling</th>\n",
       "      <th>paymentmethod</th>\n",
       "      <th>monthlycharges</th>\n",
       "      <th>totalcharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2019-12-01 00:00:00</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019-11-01 00:00:00</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid   begindate              enddate            type  \\\n",
       "0  7590-VHVEG  2020-01-01                   No  Month-to-month   \n",
       "1  5575-GNVDE  2017-04-01                   No        One year   \n",
       "2  3668-QPYBK  2019-10-01  2019-12-01 00:00:00  Month-to-month   \n",
       "3  7795-CFOCW  2016-05-01                   No        One year   \n",
       "4  9237-HQITU  2019-09-01  2019-11-01 00:00:00  Month-to-month   \n",
       "\n",
       "  paperlessbilling              paymentmethod  monthlycharges totalcharges  \n",
       "0              Yes           Electronic check           29.85        29.85  \n",
       "1               No               Mailed check           56.95       1889.5  \n",
       "2              Yes               Mailed check           53.85       108.15  \n",
       "3               No  Bank transfer (automatic)           42.30      1840.75  \n",
       "4              Yes           Electronic check           70.70       151.65  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'internet'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5517, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>internetservice</th>\n",
       "      <th>onlinesecurity</th>\n",
       "      <th>onlinebackup</th>\n",
       "      <th>deviceprotection</th>\n",
       "      <th>techsupport</th>\n",
       "      <th>streamingtv</th>\n",
       "      <th>streamingmovies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid internetservice onlinesecurity onlinebackup deviceprotection  \\\n",
       "0  7590-VHVEG             DSL             No          Yes               No   \n",
       "1  5575-GNVDE             DSL            Yes           No              Yes   \n",
       "2  3668-QPYBK             DSL            Yes          Yes               No   \n",
       "3  7795-CFOCW             DSL            Yes           No              Yes   \n",
       "4  9237-HQITU     Fiber optic             No           No               No   \n",
       "\n",
       "  techsupport streamingtv streamingmovies  \n",
       "0          No          No              No  \n",
       "1          No          No              No  \n",
       "2          No          No              No  \n",
       "3         Yes          No              No  \n",
       "4          No          No              No  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'personal'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7043, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>gender</th>\n",
       "      <th>seniorcitizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid  gender  seniorcitizen partner dependents\n",
       "0  7590-VHVEG  Female              0     Yes         No\n",
       "1  5575-GNVDE    Male              0      No         No\n",
       "2  3668-QPYBK    Male              0      No         No\n",
       "3  7795-CFOCW    Male              0      No         No\n",
       "4  9237-HQITU  Female              0      No         No"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'phone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6361, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>multiplelines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9305-CDSKC</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1452-KIOVK</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid multiplelines\n",
       "0  5575-GNVDE            No\n",
       "1  3668-QPYBK            No\n",
       "2  9237-HQITU            No\n",
       "3  9305-CDSKC           Yes\n",
       "4  1452-KIOVK           Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data_set in data_dict:\n",
    "    df = data_dict[data_set]\n",
    "    display(data_set, df.shape, df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "#### Question\n",
    "__What should be our target?__<br>\n",
    "Client wants to know whether a clint gonna churn next month.<br>\n",
    "EndDate field suits that purpose. Existing date - will churn, 'No' - will not.<br>\n",
    "For the purpose of model training we should create a new field, assigning True for churn, and false for the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    5174\n",
       "True     1869\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contract_data['target'] = (contract_data['enddate'] != 'No')\n",
    "contract_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "#### Question\n",
    "Classes are unbalanced.\n",
    "__Should we use upsampling, downsampling or some other method of class balancing?__<br>\n",
    "We probably will test those options during the model training. However, having limited data, downsampling seems problematic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect data shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contract   shape: (7043, 9)\n",
      "internet   shape: (5517, 8)\n",
      "personal   shape: (7043, 5)\n",
      "phone      shape: (6361, 2)\n"
     ]
    }
   ],
   "source": [
    "for data_set in data_dict:\n",
    "    df = data_dict[data_set]\n",
    "    df.columns = df.columns.str.lower()\n",
    "    print(f\"{data_set:<10} shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "#### Question. \n",
    "Internet and phone data contains less entries than contract and personal data. __How should we take care of those missing values?<br>__\n",
    "This is happening probably due to some customers using only phone or only internet services.<br>\n",
    "During the stage, where we merge all the data into one table, missing values should probably be filled with a placeholder meaning user do not use this particular service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data types and inspect for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contract'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "customerid           object\n",
       "begindate            object\n",
       "enddate              object\n",
       "type                 object\n",
       "paperlessbilling     object\n",
       "paymentmethod        object\n",
       "monthlycharges      float64\n",
       "totalcharges         object\n",
       "target                 bool\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values were found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'internet'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "customerid          object\n",
       "internetservice     object\n",
       "onlinesecurity      object\n",
       "onlinebackup        object\n",
       "deviceprotection    object\n",
       "techsupport         object\n",
       "streamingtv         object\n",
       "streamingmovies     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values were found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'personal'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "customerid       object\n",
       "gender           object\n",
       "seniorcitizen     int64\n",
       "partner          object\n",
       "dependents       object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values were found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'phone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "customerid       object\n",
       "multiplelines    object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values were found\n"
     ]
    }
   ],
   "source": [
    "for data_set in data_dict:\n",
    "    df = data_dict[data_set]\n",
    "    display(data_set, df.dtypes)\n",
    "    print(\"No missing values were found\" if df.isna().sum().sum() == 0 else \"Found missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_charges_to_int(total_charges):\n",
    "    \"\"\"Convert object values of total charges to float\n",
    "    \n",
    "    :param row: Total charges value as object\n",
    "    :return: Value converted to float or 0\n",
    "    \n",
    "    >>> total_charges_to_int('123.4')\n",
    "    123.4\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(total_charges)\n",
    "    except:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "charges = contract_data['totalcharges'].apply(total_charges_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "We found no missng values inside provided data.<br>\n",
    "However data types in some instances do not fit.\n",
    "#### Questions:\n",
    "- Begin date and end date are objects, not datetime. In addition enddate field has object values 'No'. __How we should process them?__\n",
    "    - Option one: Leave them be, as we are probably gonna use them to extract contract length, to use as a feature, and will not use further. And target was already extracted from the enddate field.\n",
    "    - Option two: Replace 'No' values with actual date(2020-02-01)\n",
    "- Total charges field should be of type float, but we have empty values. \n",
    "    - __Should we ommit those records or set them to 0?__ Having contract length of 0 those records could distort our data.\n",
    "- As for other values, __how should we process missing values that we will get while merging data?__\n",
    "    - Such values should be replaced with values like 'None'. ex. internet service field would have three possible values: 'fiber', 'DSL', 'None' - for customers who do not use this service.\n",
    "    - Additionally we should double check for customers, not using any service, to be shure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "#### Question.\n",
    "__What features should we use?__<br>\n",
    "- Which services provided the company customer uses and billing details.\n",
    "    - We will have to assign values for services customer do not use and categorize those fields\n",
    "- Length of contract\n",
    "- Monthly payment\n",
    "    - Total payment is ommited, as redundant. As it is most likely a product of monthly payment nultiplyed by contract length\n",
    "\n",
    "- Date fields are used to extract target and features and will not be used further\n",
    "- Customer Id is just a unique identificator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions summary\n",
    "- What should we use as a target? [here](#1)\n",
    "- How should we process class imballance? [here](#2)\n",
    "- As we merge data, we will have missing values. How shoud we process them? [here](#3)\n",
    "- How should we process data types? [here](#4)\n",
    "- What features will we use for model training? [here](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Plan:\n",
    "- [Download and inspect the data](#load_data)\n",
    "- [Merge tables, fill missing values and fix data types](#preprocess)\n",
    "- [Extract target and features](#feature_extraction)\n",
    "- Model training\n",
    "    - [Encode and scale features. Split data into train and test sets](#train_test_split)\n",
    "    - [Model training](#models)\n",
    "- [Performance evaluation](#evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocess'></a>\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "customerid             0\n",
       "begindate              0\n",
       "enddate                0\n",
       "type                   0\n",
       "paperlessbilling       0\n",
       "paymentmethod          0\n",
       "monthlycharges         0\n",
       "totalcharges           0\n",
       "target                 0\n",
       "gender                 0\n",
       "seniorcitizen          0\n",
       "partner                0\n",
       "dependents             0\n",
       "multiplelines        682\n",
       "internetservice     1526\n",
       "onlinesecurity      1526\n",
       "onlinebackup        1526\n",
       "deviceprotection    1526\n",
       "techsupport         1526\n",
       "streamingtv         1526\n",
       "streamingmovies     1526\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = contract_data.merge(personal_data, how='outer').merge(phone_data, how='outer').merge(internet_data, how='outer')\n",
    "\n",
    "print(full_data.shape)\n",
    "# Check for missing values\n",
    "full_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if there are customers that do not use any services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no 'dead' customers\n"
     ]
    }
   ],
   "source": [
    "phone_services = phone_data.columns.to_list()\n",
    "phone_services.remove('customerid')\n",
    "internet_services = internet_data.columns.to_list()\n",
    "internet_services.remove('customerid')\n",
    "\n",
    "# look for customers with missing values in all fields related to provided services\n",
    "if (pd.isnull(full_data[phone_services+internet_services]).sum(axis=1) > 7).sum() != 0:\n",
    "    print(\"There are customers that do not use any services\")\n",
    "else:\n",
    "    print(\"There are no 'dead' customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values in columns with multiple choice will be replaced with \"None\"<br>\n",
    "While missing values in columns with binary choice(online security, online backup etc) will be replaced with \"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values were successfully filled\n"
     ]
    }
   ],
   "source": [
    "# multiple lines possible values: Yes - multiple lines, No - single line, None - no lines\n",
    "# internet service possible values: DSL, Fiber, None - do not use this service\n",
    "multiple_choice = ['multiplelines', 'internetservice']\n",
    "# fields below have two options Yes - service in use, No - service not in use\n",
    "binary_choice = ['onlinesecurity', 'onlinebackup', 'deviceprotection', 'techsupport', 'streamingtv', 'streamingmovies']\n",
    "\n",
    "full_data[multiple_choice] = full_data[multiple_choice].fillna('None')\n",
    "full_data[binary_choice] = full_data[binary_choice].fillna('No')\n",
    "\n",
    "if full_data.isna().sum().sum() == 0:\n",
    "    print(\"Missing values were successfully filled\")\n",
    "else:\n",
    "    print(\"Some missing values still remain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features =  full_data.columns.to_list()\n",
    "num_features = ['monthlycharges', 'duration']\n",
    "\n",
    "# convert object fields to category\n",
    "for column in ['customerid', 'begindate', 'enddate', 'monthlycharges', 'totalcharges', 'target']: cat_features.remove(column)\n",
    "full_data[cat_features] = full_data[cat_features].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract contract length from dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_turn(row):\n",
    "    \"\"\" Calculate contract length till turner, or actual date in days\n",
    "    \n",
    "    :param row: Data Frame row\n",
    "    :return: End date minus begin date\n",
    "    \n",
    "    >>> calc_turn(['2020-01-01', '2020-01-10'])\n",
    "    9\n",
    "    \"\"\"\n",
    "    begin = pd.to_datetime(row['begindate'])\n",
    "    try:\n",
    "        end = pd.to_datetime(row['enddate'])\n",
    "    except:\n",
    "        # end = date.today()\n",
    "        end = pd.to_datetime('2020-02-01')\n",
    "    return (end - begin).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['duration'] = full_data.apply(calc_turn, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = full_data[num_features + cat_features]\n",
    "target = full_data['target'] * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "- We've merged provided data\n",
    "- Filled missing values caused by merging tables that didn't have data in customers who do not use certain services\n",
    "- Changed data types\n",
    "- Used dates of beginning and ending the contract to calculate contract length\n",
    "- Extracted features and target to separate data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train_test_split'></a>\n",
    "## Model training\n",
    "### Encode categorical feartures and split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to save model performance\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set have 26.41% True targets\n",
      "Test set have 26.92% True targets\n"
     ]
    }
   ],
   "source": [
    "# encode categorical features\n",
    "ohe_fearures = pd.get_dummies(features[cat_features], drop_first=True)\n",
    "# join with numerical features\n",
    "ohe_features = ohe_fearures.join(features[num_features])\n",
    "# split and check for class 1 share in each set\n",
    "train_features, test_features, train_target, test_target = train_test_split(ohe_features, target, test_size=0.25, random_state = RANDOM_STATE)\n",
    "print(f\"Train set have {train_target.sum()/train_target.shape[0]:.2%} True targets\")\n",
    "print(f\"Test set have {test_target.sum()/test_target.shape[0]:.2%} True targets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-e7bd5775e40b>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_features[num_features] = scaler.transform(train_features[num_features])\n",
      "<ipython-input-21-e7bd5775e40b>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_features[num_features] = scaler.transform(test_features[num_features])\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_features[num_features])\n",
    "train_features[num_features] = scaler.transform(train_features[num_features])\n",
    "test_features[num_features] = scaler.transform(test_features[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'></a>\n",
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, train_features, train_target, test_features, test_target, results):\n",
    "    \"\"\" Train and test model. Save results and train/prediction times to dictionary\n",
    "    \n",
    "    :param model: Model for training\n",
    "    :param model_name: Name for dictionary entrie\n",
    "    :param train_features: Training features\n",
    "    :param train_traget: Training target\n",
    "    :param test_features: Test features\n",
    "    :param test_target: Test target\n",
    "    :param results: Results dictionary\n",
    "    \"\"\"\n",
    "    # create dictionary entrie for a model\n",
    "    results[model_name] = {}\n",
    "    # train and record training time\n",
    "    begin = Timer()\n",
    "    model.fit(train_features, train_target)\n",
    "    end = Timer()\n",
    "    results[model_name]['train time'] = end - begin\n",
    "    \n",
    "    predictions_train = model.predict_proba(train_features)[:, 1]\n",
    "    # make predictions for a test set and record prediction time\n",
    "    begin = Timer()\n",
    "    predictions_test = model.predict_proba(test_features)[:, 1]\n",
    "    end = Timer()\n",
    "    results[model_name]['predict time'] = end - begin\n",
    "    # save roc-auc score for train and test predictions\n",
    "    results[model_name]['roc-auc train'] = roc_auc_score(train_target, predictions_train)\n",
    "    results[model_name]['roc-auc test'] = roc_auc_score(test_target, predictions_test)\n",
    "    results[model_name]['f1 train'] = f1_score(train_target, model.predict(train_features))\n",
    "    results[model_name]['f1 test'] = f1_score(test_target, model.predict(test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will declare model, pass it to this function with needed data, then repeat until satisfied :)<br>\n",
    "\n",
    "[skip to results](#evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier()\n",
    "\n",
    "evaluate_model(dummy, 'Dummy', train_features, train_target, test_features, test_target, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=RANDOM_STATE, solver='liblinear')\n",
    "\n",
    "evaluate_model(lr, 'Logistic Regression', train_features, train_target, test_features, test_target, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regressoion (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrb = LogisticRegression(random_state=RANDOM_STATE, class_weight='balanced', solver='liblinear')\n",
    "\n",
    "evaluate_model(lrb, 'Logistic Regression (Balanced)', train_features, train_target, test_features, test_target, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression (Upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_set(features, target):\n",
    "    \"\"\" Upsamples less represented class, shuffles and returns features and target\n",
    "    \n",
    "    :param features: Features of unbalanced data set\n",
    "    :param target: Target of unbalanced data set\n",
    "    :return: Balanced features and target\n",
    "    \"\"\"\n",
    "    # Split by class\n",
    "    features_true = features[target==True]\n",
    "    features_false = features[target==False]\n",
    "    \n",
    "    target_true = target[target==True]\n",
    "    target_false = target[target==False]\n",
    "    # Repeat underrepresented class and join with the second class\n",
    "    if len(target_false) > len(target_true):\n",
    "        ratio = int(len(target_false) / len(target_true))\n",
    "        features_upsampled = pd.concat([features_false] + [features_true] * ratio)\n",
    "        target_upsampled = pd.concat([target_false] + [target_true] * ratio)\n",
    "    else:\n",
    "        ratio = int(len(target_true) / len(target_false))\n",
    "        features_upsampled = pd.concat([features_true] + [features_false] * ratio)\n",
    "        target_upsampled = pd.concat([target_true] + [target_false] * ratio)\n",
    "    # Shuffle and return\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=RANDOM_STATE)\n",
    "    return features_upsampled, target_upsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_features, up_target = upsample_set(train_features, train_target)\n",
    "\n",
    "lru = LogisticRegression(random_state=RANDOM_STATE, solver='liblinear')\n",
    "\n",
    "evaluate_model(lru, 'Logistic Regression (Upsampled)', up_features, up_target, test_features, test_target, results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': range(3, 20, 2), 'min_samples_split' : range(2, 20, 2)}\n",
    "dtc = GridSearchCV(DecisionTreeClassifier(random_state=RANDOM_STATE), parameters, cv=4, scoring = 'roc_auc')\n",
    "\n",
    "evaluate_model(dtc, 'Decision Tree Classifier', train_features, train_target, test_features, test_target, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': range(3, 20, 2), 'min_samples_split' : range(2, 20, 2)}\n",
    "dtcb = GridSearchCV(DecisionTreeClassifier(random_state=RANDOM_STATE, class_weight='balanced'), parameters, cv=4, scoring = 'roc_auc')\n",
    "\n",
    "evaluate_model(dtcb, 'Decision Tree Classifier (Balanced)', train_features, train_target, test_features, test_target, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree (Upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_features, up_target = upsample_set(train_features, train_target)\n",
    "\n",
    "parameters = {'max_depth': range(3, 20, 2), 'min_samples_split' : range(2, 20, 2)}\n",
    "dtcu = GridSearchCV(DecisionTreeClassifier(random_state=RANDOM_STATE), parameters, cv=4, scoring = 'roc_auc')\n",
    "\n",
    "evaluate_model(dtcu, 'Decision Tree Classifier (Upsampled)', up_features, up_target, test_features, test_target, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': [100], 'max_depth': range(3, 20, 2), 'min_samples_split' : range(2, 20, 2)}\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=RANDOM_STATE), parameters, cv=5, scoring = 'roc_auc')\n",
    "\n",
    "evaluate_model(rf, 'Random Forest Classifier', train_features, train_target, test_features, test_target, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': [100], 'max_depth': range(3, 20, 2), 'min_samples_split' : range(2, 20, 2)}\n",
    "rfb = GridSearchCV(RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced'), parameters, cv=5, scoring = 'roc_auc')\n",
    "\n",
    "evaluate_model(rfb, 'Random Forest Classifier (Balanced)', train_features, train_target, test_features, test_target, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest (Upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_features, up_target = upsample_set(train_features, train_target)\n",
    "\n",
    "parameters = {'n_estimators': [100], 'max_depth': range(3, 20, 2), 'min_samples_split' : range(2, 20, 2)}\n",
    "rfu = GridSearchCV(RandomForestClassifier(random_state=RANDOM_STATE), parameters, cv=5, scoring = 'roc_auc')\n",
    "\n",
    "evaluate_model(rfu, 'Random Forest Classifier (Upsampled)', up_features, up_target, test_features, test_target, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'learning_rate' : np.arange(0.05, 0.2, 0.05), 'verbose': [0]}\n",
    "# cat = GridSearchCV(CatBoostClassifier(random_state=RANDOM_STATE, loss_function='Logloss'), parameters, cv=3, scoring = 'roc_auc')\n",
    "cat = CatBoostClassifier(random_state=RANDOM_STATE, loss_function='Logloss', verbose=0)\n",
    "evaluate_model(cat, 'CatBoost Classifier', train_features, train_target, test_features, test_target, results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catboost (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(train_target)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_target)\n",
    "\n",
    "# parameters = {'learning_rate' : np.arange(0.05, 0.2, 0.05), 'verbose': [0]}\n",
    "# catb = GridSearchCV(CatBoostClassifier(random_state=RANDOM_STATE, loss_function='Logloss', class_weights=weights), parameters, cv=3, scoring = 'roc_auc')\n",
    "catb = CatBoostClassifier(random_state=RANDOM_STATE, loss_function='Logloss', class_weights=weights, verbose=0)\n",
    "evaluate_model(catb, 'CatBoost Classifier (Balanced)', train_features, train_target, test_features, test_target, results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost (Upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_features, up_target = upsample_set(train_features, train_target)\n",
    "\n",
    "# parameters = {'learning_rate' : np.arange(0.05, 0.2, 0.05), 'verbose': [0]}\n",
    "# catb = GridSearchCV(CatBoostClassifier(random_state=RANDOM_STATE, loss_function='Logloss', class_weights=weights), parameters, cv=3, scoring = 'roc_auc')\n",
    "catu = CatBoostClassifier(random_state=RANDOM_STATE, loss_function='Logloss', verbose=0)\n",
    "evaluate_model(catu, 'CatBoost Classifier (Upsampled)', up_features, up_target, test_features, test_target, results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='evaluation'></a>\n",
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{'model':^40}|{'train roc-auc':>15}|{'test roc-auc':>15}|{'train time':>15}|{'predict time':>15}|\")\n",
    "# print('-' * 105)\n",
    "# for model in results:\n",
    "#     entrie = results[model]\n",
    "#     try:\n",
    "#         print(f\"{model:^40}|{entrie['roc-auc train']:>15.4f}|{entrie['roc-auc test']:>15.4f}|{entrie['train time']:>15.4f}|{entrie['predict time']:>15.4f}|\")\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train time</th>\n",
       "      <th>predict time</th>\n",
       "      <th>roc-auc train</th>\n",
       "      <th>roc-auc test</th>\n",
       "      <th>f1 train</th>\n",
       "      <th>f1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.049841</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.848404</td>\n",
       "      <td>0.838684</td>\n",
       "      <td>0.593493</td>\n",
       "      <td>0.590542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (Balanced)</th>\n",
       "      <td>0.024877</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.848286</td>\n",
       "      <td>0.839121</td>\n",
       "      <td>0.630503</td>\n",
       "      <td>0.629660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (Upsampled)</th>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.848422</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.724741</td>\n",
       "      <td>0.628781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>4.355032</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.858697</td>\n",
       "      <td>0.839191</td>\n",
       "      <td>0.639425</td>\n",
       "      <td>0.625821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier (Balanced)</th>\n",
       "      <td>4.630971</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.886608</td>\n",
       "      <td>0.844780</td>\n",
       "      <td>0.672803</td>\n",
       "      <td>0.627622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier (Upsampled)</th>\n",
       "      <td>5.266313</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.970840</td>\n",
       "      <td>0.765837</td>\n",
       "      <td>0.878189</td>\n",
       "      <td>0.589796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>157.719275</td>\n",
       "      <td>0.034237</td>\n",
       "      <td>0.911962</td>\n",
       "      <td>0.854969</td>\n",
       "      <td>0.658364</td>\n",
       "      <td>0.591961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier (Balanced)</th>\n",
       "      <td>190.623289</td>\n",
       "      <td>0.033212</td>\n",
       "      <td>0.912105</td>\n",
       "      <td>0.853357</td>\n",
       "      <td>0.713206</td>\n",
       "      <td>0.646801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier (Upsampled)</th>\n",
       "      <td>172.449492</td>\n",
       "      <td>0.040629</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.835719</td>\n",
       "      <td>0.996064</td>\n",
       "      <td>0.612766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost Classifier</th>\n",
       "      <td>3.794536</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.962755</td>\n",
       "      <td>0.908307</td>\n",
       "      <td>0.806503</td>\n",
       "      <td>0.716489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost Classifier (Balanced)</th>\n",
       "      <td>3.693474</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.965153</td>\n",
       "      <td>0.904354</td>\n",
       "      <td>0.814304</td>\n",
       "      <td>0.715888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost Classifier (Upsampled)</th>\n",
       "      <td>4.019670</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.972917</td>\n",
       "      <td>0.911460</td>\n",
       "      <td>0.896057</td>\n",
       "      <td>0.733740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      train time  predict time  roc-auc train  \\\n",
       "Dummy                                   0.000963      0.000175       0.500000   \n",
       "Logistic Regression                     0.049841      0.002004       0.848404   \n",
       "Logistic Regression (Balanced)          0.024877      0.002278       0.848286   \n",
       "Logistic Regression (Upsampled)         0.029883      0.001754       0.848422   \n",
       "Decision Tree Classifier                4.355032      0.001389       0.858697   \n",
       "Decision Tree Classifier (Balanced)     4.630971      0.001138       0.886608   \n",
       "Decision Tree Classifier (Upsampled)    5.266313      0.001346       0.970840   \n",
       "Random Forest Classifier              157.719275      0.034237       0.911962   \n",
       "Random Forest Classifier (Balanced)   190.623289      0.033212       0.912105   \n",
       "Random Forest Classifier (Upsampled)  172.449492      0.040629       0.999979   \n",
       "CatBoost Classifier                     3.794536      0.004040       0.962755   \n",
       "CatBoost Classifier (Balanced)          3.693474      0.004709       0.965153   \n",
       "CatBoost Classifier (Upsampled)         4.019670      0.002313       0.972917   \n",
       "\n",
       "                                      roc-auc test  f1 train   f1 test  \n",
       "Dummy                                     0.500000  0.000000  0.000000  \n",
       "Logistic Regression                       0.838684  0.593493  0.590542  \n",
       "Logistic Regression (Balanced)            0.839121  0.630503  0.629660  \n",
       "Logistic Regression (Upsampled)           0.839002  0.724741  0.628781  \n",
       "Decision Tree Classifier                  0.839191  0.639425  0.625821  \n",
       "Decision Tree Classifier (Balanced)       0.844780  0.672803  0.627622  \n",
       "Decision Tree Classifier (Upsampled)      0.765837  0.878189  0.589796  \n",
       "Random Forest Classifier                  0.854969  0.658364  0.591961  \n",
       "Random Forest Classifier (Balanced)       0.853357  0.713206  0.646801  \n",
       "Random Forest Classifier (Upsampled)      0.835719  0.996064  0.612766  \n",
       "CatBoost Classifier                       0.908307  0.806503  0.716489  \n",
       "CatBoost Classifier (Balanced)            0.904354  0.814304  0.715888  \n",
       "CatBoost Classifier (Upsampled)           0.911460  0.896057  0.733740  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(results).transpose()\n",
    "# table.sort_values(by='roc-auc test', ascending=False)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "- We've encoded categorical features\n",
    "- Split data into train and test data sets\n",
    "- Scaled numerical features\n",
    "- Trained couple of models, recording their performance\n",
    "    - Dummy Classifier\n",
    "    - Logistic Regression. With optional class balancing.\n",
    "    - Decision Tree Classifier. With hyperparameter tuning and optional class balancing.\n",
    "    - Random Forest Classifier. With hyperparameter tuning and optional class balancing.\n",
    "    - CatBoostClassifier. With optional class balancing. Tuning learning rate took a long time while affecting performance very slightly, so ommited it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation\n",
    "- CatboostClassifier delivered best results while maintaining adequate training and prediction times. \n",
    "- Using built-in balancing feature helped improving Logistic Regression and Decision Tree performance, while worsening the score of Random Fores and  CatBoost.\n",
    "- Upsampling worked even worse with Decision Tree and Random Forest, but improved slightly CatBoost score.\n",
    "\n",
    "Overall CatBoost did a great job and is recomended for use with class upsampling. Performance is best around the table, while timings are still reasonable, even if it would be necessary to perform this process once a month with larger pool of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 612,
    "start_time": "2022-01-28T20:41:24.290Z"
   },
   {
    "duration": 3592,
    "start_time": "2022-01-28T20:42:01.688Z"
   },
   {
    "duration": 1200,
    "start_time": "2022-01-28T20:42:05.282Z"
   },
   {
    "duration": 2419,
    "start_time": "2022-01-28T20:43:12.207Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-28T20:43:14.628Z"
   },
   {
    "duration": 135,
    "start_time": "2022-01-28T20:43:14.635Z"
   },
   {
    "duration": 41,
    "start_time": "2022-01-28T20:43:14.772Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-28T20:43:14.814Z"
   },
   {
    "duration": 24,
    "start_time": "2022-01-28T20:43:14.823Z"
   },
   {
    "duration": 22,
    "start_time": "2022-01-28T20:43:14.849Z"
   },
   {
    "duration": 51,
    "start_time": "2022-01-28T20:43:14.873Z"
   },
   {
    "duration": 3,
    "start_time": "2022-01-28T20:43:14.927Z"
   },
   {
    "duration": 116,
    "start_time": "2022-01-28T20:43:14.933Z"
   },
   {
    "duration": 39,
    "start_time": "2022-01-28T20:43:15.051Z"
   },
   {
    "duration": 10,
    "start_time": "2022-01-28T20:43:15.092Z"
   },
   {
    "duration": 33,
    "start_time": "2022-01-28T20:43:15.104Z"
   },
   {
    "duration": 34,
    "start_time": "2022-01-28T20:43:15.139Z"
   },
   {
    "duration": 3,
    "start_time": "2022-01-28T20:43:15.175Z"
   },
   {
    "duration": 3517,
    "start_time": "2022-01-28T20:43:15.179Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-28T20:43:18.697Z"
   },
   {
    "duration": 26,
    "start_time": "2022-01-28T20:43:18.705Z"
   },
   {
    "duration": 49,
    "start_time": "2022-01-28T20:43:18.732Z"
   },
   {
    "duration": 18,
    "start_time": "2022-01-28T20:44:34.083Z"
   },
   {
    "duration": 7,
    "start_time": "2022-01-28T20:44:38.458Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-28T20:44:41.936Z"
   },
   {
    "duration": 101,
    "start_time": "2022-01-28T20:44:44.770Z"
   },
   {
    "duration": 27,
    "start_time": "2022-01-28T20:44:46.162Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-28T20:47:23.235Z"
   },
   {
    "duration": 2362,
    "start_time": "2022-01-28T20:47:35.376Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-28T20:47:37.741Z"
   },
   {
    "duration": 98,
    "start_time": "2022-01-28T20:47:37.749Z"
   },
   {
    "duration": 35,
    "start_time": "2022-01-28T20:47:37.849Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-28T20:47:37.886Z"
   },
   {
    "duration": 9,
    "start_time": "2022-01-28T20:47:37.895Z"
   },
   {
    "duration": 7,
    "start_time": "2022-01-28T20:47:37.905Z"
   },
   {
    "duration": 63,
    "start_time": "2022-01-28T20:47:37.914Z"
   },
   {
    "duration": 3,
    "start_time": "2022-01-28T20:47:37.979Z"
   },
   {
    "duration": 101,
    "start_time": "2022-01-28T20:47:37.983Z"
   },
   {
    "duration": 36,
    "start_time": "2022-01-28T20:47:38.085Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-28T20:47:38.122Z"
   },
   {
    "duration": 43,
    "start_time": "2022-01-28T20:47:38.131Z"
   },
   {
    "duration": 28,
    "start_time": "2022-01-28T20:47:38.175Z"
   },
   {
    "duration": 3,
    "start_time": "2022-01-28T20:47:38.204Z"
   },
   {
    "duration": 3425,
    "start_time": "2022-01-28T20:47:38.209Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-28T20:47:41.636Z"
   },
   {
    "duration": 4,
    "start_time": "2022-01-28T20:47:41.643Z"
   },
   {
    "duration": 27,
    "start_time": "2022-01-28T20:47:41.661Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-28T20:47:41.689Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-28T20:47:41.705Z"
   },
   {
    "duration": 17,
    "start_time": "2022-01-28T20:47:41.712Z"
   },
   {
    "duration": 329,
    "start_time": "2022-01-28T20:47:41.732Z"
   },
   {
    "duration": 207,
    "start_time": "2022-01-28T20:47:42.063Z"
   },
   {
    "duration": 93,
    "start_time": "2022-01-28T20:47:42.272Z"
   },
   {
    "duration": 297,
    "start_time": "2022-01-28T20:47:42.367Z"
   },
   {
    "duration": 4691,
    "start_time": "2022-01-28T20:47:42.666Z"
   },
   {
    "duration": 4737,
    "start_time": "2022-01-28T20:47:47.360Z"
   },
   {
    "duration": 5441,
    "start_time": "2022-01-28T20:47:52.099Z"
   },
   {
    "duration": 114879,
    "start_time": "2022-01-28T20:47:57.542Z"
   },
   {
    "duration": 116138,
    "start_time": "2022-01-28T20:49:52.423Z"
   },
   {
    "duration": 136586,
    "start_time": "2022-01-28T20:51:48.563Z"
   },
   {
    "duration": 21597,
    "start_time": "2022-01-28T20:54:05.151Z"
   },
   {
    "duration": 4,
    "start_time": "2022-01-28T20:54:26.746Z"
   },
   {
    "duration": -1,
    "start_time": "2022-01-28T20:54:26.752Z"
   },
   {
    "duration": 17,
    "start_time": "2022-01-28T20:58:14.621Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-28T20:58:33.225Z"
   },
   {
    "duration": 20852,
    "start_time": "2022-01-28T20:59:08.133Z"
   },
   {
    "duration": 17,
    "start_time": "2022-01-28T20:59:43.374Z"
   },
   {
    "duration": 271,
    "start_time": "2022-01-28T21:00:05.991Z"
   },
   {
    "duration": 9,
    "start_time": "2022-01-28T21:00:23.126Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-28T21:00:37.549Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-28T21:00:47.319Z"
   },
   {
    "duration": 433,
    "start_time": "2022-01-28T21:01:07.235Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-28T21:01:19.981Z"
   },
   {
    "duration": 7,
    "start_time": "2022-01-28T21:01:52.337Z"
   },
   {
    "duration": 38626,
    "start_time": "2022-01-28T21:02:18.569Z"
   },
   {
    "duration": 7,
    "start_time": "2022-01-28T21:02:57.197Z"
   },
   {
    "duration": 15,
    "start_time": "2022-01-28T21:03:19.728Z"
   },
   {
    "duration": 23697,
    "start_time": "2022-01-28T21:03:34.537Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-28T21:03:58.236Z"
   },
   {
    "duration": 21,
    "start_time": "2022-01-28T21:03:58.244Z"
   },
   {
    "duration": 249,
    "start_time": "2022-01-28T21:04:45.452Z"
   },
   {
    "duration": 11,
    "start_time": "2022-01-28T21:04:51.319Z"
   },
   {
    "duration": 2475,
    "start_time": "2022-01-28T21:05:44.850Z"
   },
   {
    "duration": 1260,
    "start_time": "2022-01-28T21:05:47.328Z"
   },
   {
    "duration": 97,
    "start_time": "2022-01-28T21:05:48.591Z"
   },
   {
    "duration": 38,
    "start_time": "2022-01-28T21:05:48.689Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-28T21:05:48.728Z"
   },
   {
    "duration": 26,
    "start_time": "2022-01-28T21:05:48.737Z"
   },
   {
    "duration": 10,
    "start_time": "2022-01-28T21:05:48.765Z"
   },
   {
    "duration": 24,
    "start_time": "2022-01-28T21:05:48.776Z"
   },
   {
    "duration": 3,
    "start_time": "2022-01-28T21:05:48.803Z"
   },
   {
    "duration": 121,
    "start_time": "2022-01-28T21:05:48.807Z"
   },
   {
    "duration": 48,
    "start_time": "2022-01-28T21:05:48.930Z"
   },
   {
    "duration": 9,
    "start_time": "2022-01-28T21:05:48.980Z"
   },
   {
    "duration": 28,
    "start_time": "2022-01-28T21:05:48.991Z"
   },
   {
    "duration": 54,
    "start_time": "2022-01-28T21:05:49.021Z"
   },
   {
    "duration": 4,
    "start_time": "2022-01-28T21:05:49.077Z"
   },
   {
    "duration": 3685,
    "start_time": "2022-01-28T21:05:49.083Z"
   },
   {
    "duration": 12,
    "start_time": "2022-01-28T21:05:52.769Z"
   },
   {
    "duration": 3,
    "start_time": "2022-01-28T21:05:52.782Z"
   },
   {
    "duration": 25,
    "start_time": "2022-01-28T21:05:52.787Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-28T21:05:52.814Z"
   },
   {
    "duration": 34,
    "start_time": "2022-01-28T21:05:52.829Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-28T21:05:52.865Z"
   },
   {
    "duration": 178,
    "start_time": "2022-01-28T21:05:52.883Z"
   },
   {
    "duration": 297,
    "start_time": "2022-01-28T21:05:53.064Z"
   },
   {
    "duration": 97,
    "start_time": "2022-01-28T21:05:53.364Z"
   },
   {
    "duration": 109,
    "start_time": "2022-01-28T21:05:53.463Z"
   },
   {
    "duration": 4931,
    "start_time": "2022-01-28T21:05:53.665Z"
   },
   {
    "duration": 5028,
    "start_time": "2022-01-28T21:05:58.599Z"
   },
   {
    "duration": 5631,
    "start_time": "2022-01-28T21:06:03.629Z"
   },
   {
    "duration": 119444,
    "start_time": "2022-01-28T21:06:09.262Z"
   },
   {
    "duration": 119376,
    "start_time": "2022-01-28T21:08:08.708Z"
   },
   {
    "duration": 140511,
    "start_time": "2022-01-28T21:10:08.086Z"
   },
   {
    "duration": 20733,
    "start_time": "2022-01-28T21:12:28.599Z"
   },
   {
    "duration": 22572,
    "start_time": "2022-01-28T21:12:49.333Z"
   },
   {
    "duration": 22060,
    "start_time": "2022-01-28T21:13:11.907Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-28T21:13:50.058Z"
   },
   {
    "duration": 13,
    "start_time": "2022-01-28T21:14:57.427Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
